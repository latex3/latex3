% \iffalse
%<*driver>
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begingroup
%</driver>
%<*ins>
\iffalse meta-comment

File l3auxdata.ins Copyright (C) 2014-2023 The LaTeX Project

It may be distributed and/or modified under the conditions of the
LaTeX Project Public License (LPPL), either version 1.3c of this
license or (at your option) any later version.  The latest version
of this license is in the file

   http://www.latex-project.org/lppl.txt

This file is part of the "l3trial bundle" (The Work in LPPL)
and all files in that bundle must be distributed together.

The released version of this bundle is available from CTAN.

\fi

\input docstrip %
\askforoverwritefalse

\preamble

EXPERIMENTAL CODE

Do not distribute this file without also distributing the
source files specified above.

Do not distribute a modified version of this file.

\endpreamble
% stop docstrip adding \endinput
\postamble
\endpostamble
\keepsilent
\generate{\file{\jobname.sty}{\from{\jobname.dtx}{pkg}}}
%<ins>\endbatchfile
%</ins>
%<*driver>
\generate{\file{\jobname.sty}{\from{\jobname.dtx}{pkg,debug}}}
\nopreamble
\nopostamble
\generate{\file{\jobname.ins}{\from{\jobname.dtx}{ins}}}
\generate{\file{\jobname.drv}{\from{\jobname.dtx}{doc}}}
\generate{\file{\jobname-example-pre.tex}{\from{\jobname.dtx}{xmpl-pre}}}
\generate{\file{\jobname-example-basics.tex}{\from{\jobname.dtx}{xmpl-basics}}}
\generate{\file{\jobname-example-box}{\from{\jobname.dtx}{xmpl-box}}}
\generate{\file{\jobname-example-tree.tex}{\from{\jobname.dtx}{xmpl-tree}}}
\generate{\file{\jobname-example-code.tex}{\from{\jobname.dtx}{xmpl-code}}}
\generate{\file{\jobname-example-blob}{\from{\jobname.dtx}{xmpl-blob}}}
\generate{\file{\jobname-example-split}{\from{\jobname.dtx}{xmpl-split}}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\def\x{LaTeX2e}
\ifx\fmtname\x\else\endbatchfile\fi\endgroup
%</driver>
%<*driver|pkg>
\RequirePackage{expl3}
%</driver|pkg>
%<*driver>
\input{\jobname.drv}
%</driver>
%<*doc>

\documentclass[a4paper]{l3doc}
\usepackage{framed}
\usepackage{l3auxdata}

\input{\jobname-example-pre.tex}

\begin{document}

\ExplSyntaxOn
\auxdata_write:nn {testexpl} {expl data 1}
\auxdata_write:nn {testexpl} {expl data 2}
\ExplSyntaxOff
\csname \detokenize{auxdata_write:nn}\endcsname {testuser} {user data}
\csname \detokenize{auxdata_write:nn}\endcsname {testuser} {user data 2}

\ExplSyntaxOn
\auxdata_process_inline:nn {testuser} { \typeout{#1} }
\auxdata_process_inline:nn {testexpl} { \typeout{#1} }
\ExplSyntaxOff


\title{Multi-pass data for \LaTeX}
\author{\LaTeX3 project}
\maketitle

\tableofcontents

\clearpage
\part{Documentation}

\section{Roadmap}

\begin{itemize}
  \item
  This package was written hastily in preparation for TUG2014.
  It still needs work.
  \item
  More writing/reading algorithms need to be written to benchmark the `best' solution.
  \item
  A mode for using the regular \verb|.aux| file is necessary!
  \item
  Perhaps a proper data-structure is needed after all rather than relying on the programmer to come up with their own ideas for what and how to read and write.
\end{itemize}

\section{Auxiliary data}

Every \LaTeX{} user is aware of the way that multiple compilations are necessary to resolve tables of contents, cross-references, bibliographies, and so on.
This is because \TeX\ reads and typesets a document in a single pass, and `nonlinear' data (such as a table of contents that requires entries from later in the document) is stored in external files in between each compilation.

\LaTeX{} does not provide a general mechanism for storing data in its auxiliary files.
The main file it uses is the \texttt{.aux} file, which is written to in the kernel with commands such as:
\begin{verbatim}
  \immediate\write\@auxout{...}
\end{verbatim}
It should be noted that \verb|\@auxout| changes definition during a document; after \verb|\include|, \verb|\@auxout| will point to the auxiliary file for each \verb|\include|d file.

At both \verb|\begin{document}| and \verb|\end{document}|, the \texttt{.aux} file from the previous compilation is \verb|\input|.
This allows \LaTeX{} to inform the user when labels change from one document compilation to the next.

Some packages use the \texttt{.aux} file as well, and this can sometimes cause problems when a package is later no longer loaded; any material it inserts into the \texttt{.aux} file \emph{should} be able to execute independently from the main package (even if it's a no-op without the package present).

\section{This package}

There is a need to provide a simple programming interface to store and retrieve data in the context of multi-pass compilation.
Let's call this the `data store' for now.
Because data can be written to the data store with any conceivable catcode regime, it's important to recognise that \emph{reading} this data is fraught with peril.
Therefore, we provide an interface to define which catcode regimes we're expecting for each type of data we're writing.

\begin{function}{\auxdata_register_store:nn}
  \begin{syntax}
    \cs{auxdata_register_store:nn} \Arg{store} \Arg{catcode changes}
  \end{syntax}
  Creates a new data store named \meta{store}, which will be saved in file "\jobname.aux"\texttt{.\meta{store}}.
  When data from this store is read, the code to implement the \meta{catcode changes} will be executed.

  Any changes introduced by this second argument are not constrained to a group and therefore the contents of this argument must be very carefully controlled.
  Catcode changes \emph{must} be implemented with \verb|\char_set_catcode:nn| or similar \pkg{expl3} command to allow for resetting of catcodes once the processing is complete.

  One data store only is defined by default: \texttt{doc}, which uses `regular' document catcodes.
  If you wish to use expl3 catcodes, I recommend using the \texttt{expl} label, but this is not defined by default to save write registers.
  Use these if possible rather than creating new data stores.
\end{function}

\smallskip
\emph{Note please:} it is only necessary to create a new store for two reasons:
(1)~you need to use a different catcode regime; or
(2)~you are storing so much data that it's slowing everything else down
(this would be unusual and using a new store will only help so much).
Always remember that \TeX\ has limited write registers.


\begin{function}{\auxdata_new_tag:nn}
  \begin{syntax}
    \cs{auxdata_new_tag:nn} \Arg{tag} \Arg{store}
  \end{syntax}
  Every time data is written to the store, it uses an identifying \meta{tag}, which this function allocates.
  All data using this tag will be stored in the specified \meta{store}.
\end{function}


\begin{function}{\auxdata_write:nn,\auxdata_write_shipout:nn,\auxdata_write_shipout_x:nn}
  \begin{syntax}
    \cs{auxdata_write:nn} \Arg{tag} \Arg{balanced text}
  \end{syntax}
  Writes \meta{balanced text} to the data store with specified \meta{tag}.
  The |_write| variant does so immediately, |_shipout| puts down a whatsit node and only writes the data when shipped out, and |_shipout_x| is similar but the contents is fully expanded at shipout time (necessary to get, e.g., page numbers correct).
\end{function}

\begin{function}{\auxdata_process_inline:nn}
  \begin{syntax}
    \cs{auxdata_process_inline:nn} \Arg{tag} \Arg{inline function}
  \end{syntax}
  Retrieves all data matching \meta{tag} in the data store and applies \meta{inline function} to each matching entry.

  Note that this processing stage is not performed inside a group, and therefore can be used in a variety of places such as within tabular environments if necessary.
\end{function}

\begin{function}{\auxdata_split:n,\auxdata_split_return:}
  \begin{syntax}
    \cs{auxdata_split:n} \Arg{basename}
    \cs{auxdata_split_return:}
  \end{syntax}
  Splits the data stores to write into files with specified \meta{basename} to facilitate `partial' document processing such as with \LaTeXe's \cs{include}.
\end{function}

\section{To do}
\label{todo}

\begin{enumerate}
  \item
  Obviously tidy up warning and error messages.
  \item
  Provide a more general method for writing to the store for verbatim-type input?
  \item \label{merge}
  Provide a way to iterate over multiple tags at once.
  For example, if we had tags for ToC and LoF and wanted to produce a `merged' table of contents.
  This isn't easily possible at present without changing the way the data is written to the aux file.
\end{enumerate}

\clearpage

\StopEventually{}

\section{Implementation requirements}

Courtesy Mittelbach.

\subsection{use case 1}

collect and provide data about overall document structure (e.g., TOC,
LOT etc)

\begin{itemize}
\item [req 1.1]

   collection needs to maintain the document structure order (eg section
1 before section 2)

\item [req 1.2]

   defined portions of the data need to be accessible (e.g., not all
section levels are shown in a TOC)

\item [req 1.3]

   data may need to be made available several times (in parts), e.g., to
provide chapter TOCs

\item [req 1.4] -- less importance

   data should be easily viewable on its own. Now this may be a
requirement nobody needs other than myself, but I quite often use a
source .toc file and do something with it directly
\end{itemize}



\subsection{use case 2}

pass information about the whole document from one run to the next (e.g.
labels)

\begin{itemize}
\item [req 2.1] -- anti req \verb|:-)|

   this type of data has no requirements on preserving order as it is
used without any relation to other data from previous run

\item [req 2.2]

   individual bits of this data are being used in the next run and often
more than once. requirement from this is that data access should be fast
(constant time) and easy, so an extension to G.2 below for that type of
data
\end{itemize}


\subsection{use case 3}

   collect information about document elements to be post-processed in
external programs prior to reuse in a later run (.e.g., index data,bib
data)

\begin{itemize}
\item [req 3.1]

   relevant data (and only relevant data) needs to be made available to
external program
\end{itemize}

\subsection{General requirements (for all use cases)}

\begin{itemize}
\item [req G.1] -- non functional

   complexity of the document structure should not be limited by
implementation (as far as possible)

\item [req G.2] -- non functional

   solution should be fairly fast and preferably linear in document
complexity

\item [req G.3]

   solution should identify if document needs an additional run to
stabilize

\item [req G.4]

    solution should support partial compilation of document
\end{itemize}

\section{Addressing the implementation requirements}

\subsection{use case 1}

\emph{collect and provide data about overall document structure (e.g., TOC,
LOT etc)}

\begin{itemize}
\item [req 1.1] Maintain order.

  Satisfied provided that you don't want to mix tags.
(See todo item~\ref{merge} on page~\pageref{todo}.)

\item [req 1.2] Data subsets are accessible.

  This is not addressed in any way by the current design; however, arbitrary data may be written to a data store and extracted for whatever purpose, so this can be handled on a different level.

\item [req 1.3] Data available multiple times.

   Easy.

\item [req 1.4] Data standalone.

   All data written to separate tags files, so this is satisfied.

\end{itemize}



\subsection{use case 2}

\emph{pass information about the whole document from one run to the next (e.g.
labels)}

\begin{itemize}
\item [req 2.1] -- anti req \verb|:-)|

\item [req 2.2] Fast (constant time) data access.

We can't get around the fact that more data put into an aux file will take longer to read at the beginning of the document.

However, once this happens it is obviously possible to store individual labels (etc.) into individual macros.

\end{itemize}


\subsection{use case 3}

   \emph{collect information about document elements to be post-processed in
external programs prior to reuse in a later run (.e.g., index data,bib
data)}

\begin{itemize}
\item [req 3.1] External programs need to be able to interface with auxiliary files.

   \textcolor{red}{Not currently addressed.}
\end{itemize}

\subsection{General requirements (for all use cases)}

\begin{itemize}
\item [req G.1] Implementation should not limit document complexity.

   As in 2e, a minimal number of files are used for the data store, and these are input AtEndDocument to write new auxiliary tag files.
   Only concern with complexity is that consistency checking (see below) currently \emph{does} require reading each tag file into memory for the entirety of the document run.
   This is limited by \TeX's (small) amount of memory availability.

\item [req G.2] -- Fairly fast and preferably linear in document
complexity.

   See comments above.
   We read files in as-needed, so it's up to the macro writer to decide whether data needs to be stored in memory or read from disk.

\item [req G.3] Consistency checking.

   This is the biggest `problem' requirement.
   Since we're checking auxiliary data from within \TeX, we can't get around the fact that having more data leads to problems with either memory requirements or speed or both.

   Currently, the solution is to read each tag file as a whole into a single macro, at the beginning and end of the document, and compare them.
   This is hard-limited by an auxiliary file size somewhere north of 20\,MB (400,000 short entries), but hitting that sort of size slows down all the other processing stages significantly as well.

\item [req G.4] Partial compilation.

    Partial compilation is supported using the same mechanism as 2e.

\end{itemize}

\section{Implementation notes}

This is what happens.
\begin{enumerate}

  \item Preamble:
  \begin{enumerate}
  \item Code requests a tag to store data with.
  \item Each tag is associated with a `data store' which corresponds to a single file to be written to during the document compilation.

  Note that writing multiple tags to a single data store is encouraged to avoid opening too many files.
  \item (Data corresponding to each tag is later written to an auxiliary tag file AtEndDocument.)
  \end{enumerate}

  \item AtBeginDocument:
  \begin{enumerate}
  \item \label{enum:cache} Each auxiliary tag file is read in its entirety and its contents stored in a macro.
  \item Note that it is entirely up to the package writer if the data in this tag file is used at this point with additional setup code inserted \cs{AtBeginDocument}.
  \end{enumerate}

  \item During compilation:
  \begin{enumerate}
  \item Data is written with tags to the specified data store file.
  \item When auxiliary data is wished to be processed, the auxiliary tag file is \cs{input} with appropriate definitions for catcodes and its prefix macro.
  \end{enumerate}

  \item AtEndDocument
  \begin{enumerate}
  \item All data store files are closed.

  \item All data store files are \cs{input} with their tag macros defined to write the contents of each tag to a new auxiliary tag file.

  If there are enough write registers to do this in a single pass, only one \cs{input} is necessary; otherwise an iterative process is used for this step that minimises the number of \cs{input}s required.
  This step uses \emph{ALL} of the remaining write registers so it better be the last thing that we do!
  (P.S. it's annoying we can't reclaim now-closed write registers at this point.
   Perhaps we can.)

  \item All auxiliary tag files are read in their entirety and stored in respective macros.
  These are then checked for global differences with the tag data from previous run, stored for later at Step~\ref{enum:cache}.
  \end{enumerate}
\end{enumerate}

\subsection{Concerns}

\begin{enumerate}
  \item Having multiple catcode regimes provides flexibility but at significant cost to write registers.
        (We use two write registers per data store.)
        It's unclear whether people actually need an expl data store.
\end{enumerate}

\DocInput{l3auxdata.dtx}

\end{document}
%</doc>
% \fi
%
% \clearpage
% \section{Examples}
%
% \subsection{Preamble for the following}
% This code is inserted in the document preamble to facilite the examples to come.
% The first chunk defines some simple wrappers for later examples.
%    \begin{macrocode}
%<*xmpl-pre>
\ExplSyntaxOn

\def\auxwrite{\auxdata_write:nn}
\def\auxshipout{\auxdata_write_shipout:nn}
\def\auxshipoutx{\auxdata_write_shipout_x:nn}
\def\auxread{\auxdata_process_inline:nn}
%    \end{macrocode}
% Then we start to use the allocators.
%    \begin{macrocode}
\auxdata_register_store:nn {expl} {\ExplSyntaxOn}
\auxdata_register_store:nn {expl} {\ExplSyntaxOn}
\auxdata_register_store:nn {expl} {\ExplSyntaxOn}
\auxdata_register_store:nn {doc} {}

\auxdata_new_tag:nn {testexpl} {expl}
\auxdata_new_tag:nn {testuser} {doc}
\auxdata_new_tag:nn {foo}  {doc}
\auxdata_new_tag:nn {bar}  {doc}
\auxdata_new_tag:nn {box}  {doc}
\auxdata_new_tag:nn {tree} {doc}
\auxdata_new_tag:nn {blob1} {doc}
\auxdata_new_tag:nn {myref} {doc}
\auxdata_new_tag:nn {split1} {doc}
\auxdata_new_tag:nn {split2} {doc}
\auxdata_new_tag:nn {split3} {doc}

\ExplSyntaxOff
%</xmpl-pre>
%    \end{macrocode}
%
% \clearpage
% \subsection{The basics}
%
%    \begin{macrocode}
%<*xmpl-basics>
\auxread {foo} {\fbox{#1}}

\auxread {foo} {\fbox{#1}}

\def\sep{\def\sep{/}}
\auxread {bar} {\sep #1}

\def\sep{\gdef\sep{\\\hline}}
\begin{tabular}{|c|}
\hline
\auxread {bar} {\sep #1}
\sep
\end{tabular}

\auxwrite {foo} {some text}
\auxwrite {bar} {yum}
\auxwrite {bar} {yar}
\auxwrite {bar} {yaz}
\auxwrite {foo} {text again}
%</xmpl-basics>
%    \end{macrocode}
%
% \begin{framed}\input{\jobname-example-basics}\end{framed}
%
% \clearpage
% \subsection{Box examples}
%
%    \begin{macrocode}
%<*xmpl-box>
\newsavebox\hideme
\savebox\hideme
 {
  \auxwrite   {box} {this is some text inside a box}
  \auxshipout {box} {hidden inside a box --- never shipped out!}
 }

\begin{enumerate}
\item first time (necessary on first pass\dots)
\auxread {box} {\item #1}
\end{enumerate}

\auxshipoutx {box} {just checking shipoutx too: \thepage}
%</xmpl-box>
%    \end{macrocode}
%
% \begin{framed}\input{\jobname-example-box}\end{framed}
%
% \clearpage
% \subsection{Tree example}
%    \begin{macrocode}
%<*xmpl-tree>
\makeatletter
\def\tree#1#2{\par\hspace{#1\dimexpr 1em\relax}\csname tree#1\endcsname{#2}}
\@namedef{tree0}#1{\textbf{#1}}
\@namedef{tree1}#1{\textit{#1}}
\@namedef{tree2}#1{\textup{#1}}
\@namedef{tree3}#1{\textsf{#1}}

\begingroup
\parindent=0pt
\auxread {tree} { \tree #1 }
\endgroup

\auxwrite {tree} {{0}{fish}}
\auxwrite {tree} {{1}{head}}
\auxwrite {tree} {{1}{bowl}}
\auxwrite {tree} {{1}{soup}}
\auxwrite {tree} {{0}{fire}}
\auxwrite {tree} {{1}{firefly}}
\auxwrite {tree} {{2}{firebird}}
\auxwrite {tree} {{3}{firesong}}
%</xmpl-tree>
%    \end{macrocode}
%
% \begin{framed}\input{\jobname-example-tree}\end{framed}
%
% \clearpage
% \subsection{Labels example}
%    \begin{macrocode}
%<*xmpl-code>
\ExplSyntaxOn
\cs_new:Npn \mylabel #1#2
  {
    \auxdata_write:nn {myref} { {myref-#1-label} {#2} }
    \tl_set:cn {myref-#1-label} {#2}
  }
\cs_new:Npn \myref #1
  {
    \tl_if_exist:cTF {myref-#1-label}
      { \tl_use:c {myref-#1-label} } { [?] }
  }
\cs_new:Npn \readrefs
  { \auxdata_process_inline:nn {myref} { \tl_set:cn ##1 } }
\ExplSyntaxOff

\readrefs % normally you'd hook this into \begin{document}

\mylabel{label}{first label before text}

Here is my first label; it says: `\myref{label}'. It's defined in a single pass.

Here is a reference to my second label; it says `\myref{lebal}'. It needs a second pass because the label only comes next.

\mylabel{lebal}{second label \emph{after text}}

This is a label that spans paragraphs: `\myref{labels}' --- works?

\mylabel{labels}{label with a paragraph

and another}

more tests: \myref{sp} / \myref{char}

\mylabel{sp}{testing   spaces
and carriage returns	and tabs}
\mylabel{char}{testing colon: and colon with a space + underscore : $a_1$}
%</xmpl-code>
%    \end{macrocode}
%
% \begin{framed}\catcode`\%=5\parskip=2ex\parindent=0pt\input{\jobname-example-code}\end{framed}
%
% \clearpage
% \subsection{10000 read/writes}
%    \begin{macrocode}
%<*xmpl-blob>
\ExplSyntaxOn

Don't~ look~ here:~ check~ your~ console~ output!

\auxread {blob1} { \typeout{#1} }

\int_step_inline:nn {10000}
 {
  \auxwrite {blob1} { 1-#1 }
 }

\ExplSyntaxOff
%</xmpl-blob>
%    \end{macrocode}
%
% \begin{framed}\catcode`\%=5\parskip=2ex\parindent=0pt\input{\jobname-example-blob}\end{framed}
%
% \clearpage
%
% \subsection{Split over files}
%    \begin{macrocode}
%<*xmpl-split>
\auxwrite{split1}{split-a}
\auxwrite{split2}{split-aa}
\auxwrite{split3}{split-aaa}
\ExplSyntaxOn
\auxdata_split:n {subfile}
\ExplSyntaxOff
\auxwrite{split1}{split-b}
\auxwrite{split2}{split-bb}
\auxwrite{split3}{split-bbb}
\ExplSyntaxOn
\auxdata_main:
\ExplSyntaxOff
\auxwrite{split1}{split-c}
\auxwrite{split2}{split-cc}
\auxwrite{split3}{split-ccc}

\auxread{split1}{#1/}

\auxread{split2}{#1/}

\auxread{split3}{#1/}
%</xmpl-split>
%    \end{macrocode}
%
% \begin{framed}\catcode`\%=5\parskip=2ex\parindent=0pt\input{\jobname-example-split}\end{framed}
%
% \clearpage
% \section{Package code}
%
%    \begin{macrocode}
%<@@=auxdata>
%<*pkg>
%    \end{macrocode}
%
%    \begin{macrocode}
%<*pkg>
\ProvidesExplPackage{l3auxdata}{2018-04-30}{}
  {L3 Experimental auxiliary data}
%</pkg>
%    \end{macrocode}
%
%    \begin{macrocode}
\usepackage{expl3}
%    \end{macrocode}
%
% \paragraph{Variables and variants}
%
%    \begin{macrocode}

\tl_new:N \l_auxdata_filename_tl
\tl_new:N \g_@@_cache_tl

\tl_new:N \l_@@_internal_tl

\cs_generate_variant:Nn \prop_put:Nnn {Nxx}
\cs_set_eq:NN \auxdata:nn \use_none:nn
%    \end{macrocode}
%
%    \begin{macrocode}
\prop_new:N \g_@@_cc_prop
\prop_new:N \g_@@_tags_prop
%    \end{macrocode}
%
% \subsection{Possible additions to expl3}
%
% \begin{macro}{\iow_count_avail:}
% \verb|\newwrite -> \alloc@7\write\chardef\sixt@@n|
%    \begin{macrocode}
\cs_new:Npn \@@_iow_count_avail:
  {
    \int_eval:n { 16 - \count17 } % 2e only!!
  }
%    \end{macrocode}
% \end{macro}
%
% \begin{macro}{\prop_count_keys:N}
%    \begin{macrocode}
\cs_new:Nn \@@_prop_count_keys:N
  {
    \int_eval:n
      { 0 \prop_map_function:NN #1 \@@_prop_count:nn }
  }
\cs_new:Nn \@@_prop_count:nn { + 1 }
%    \end{macrocode}
% \end{macro}
%
% \begin{macro}{\char_catcodes_pushing:,\char_catcodes_pop:}
%    \begin{macrocode}
\prop_new:N \l_@@_catcodes_prop
\cs_new:Nn \@@_catcodes_pushing:
  {
    \cs_set_protected:Npn \char_set_catcode:nn ##1 ##2
      {
        \prop_put:Nee \l_@@_catcodes_prop
          { \int_eval:n {##1} }
          { \tex_the:D \tex_catcode:D \int_eval:n {##1} }
        \tex_catcode:D \int_eval:n {##1} = \int_eval:n {##2} \exp_stop_f:
      }
  }
%    \end{macrocode}
%
%    \begin{macrocode}
\cs_new:Nn \@@_catcodes_pop:
  {
    \cs_set_protected:Npn \char_set_catcode:nn ##1 ##2
      { \tex_catcode:D \int_eval:n {##1} = \int_eval:n {##2} \exp_stop_f: }
    \prop_map_inline:Nn \l_@@_catcodes_prop
      { \char_set_catcode:nn {##1} {##2} }
    \prop_clear:N \l_@@_catcodes_prop
  }
%    \end{macrocode}
% \end{macro}
%
% \subsection{Allocation}
%
% \begin{macro}{\auxdata_register_store:nn}
%    \begin{macrocode}
\cs_new:Nn \auxdata_register_store:nn
  {
    \prop_if_in:NnTF \g_@@_cc_prop {#1}
      {
        \prop_get:NnN \g_@@_cc_prop {#1} \l_@@_tmp_tl
        \exp_args:No \tl_if_eq:nnF
          \l_@@_tmp_tl
          {#2 \char_set_catcode_comment:N \%}% same as below of course
          { \ERROR1 }
      }
      {
        \ior_new:c { g_auxdata_ #1 _main_stream }
        \ior_new:c { g_auxdata_ #1 _altn_stream }
        \seq_new:c { g_@@_cctags_ #1 _seq }
        \prop_gput:Nnn \g_@@_cc_prop {#1} {#2 \char_set_catcode_comment:N \%}
      }
  }
\AtEndOfPackage{ \auxdata_register_store:nn {doc} {} }
%    \end{macrocode}
% TODO: this store should ENFORCE the use of document catcodes, not assume them.
% \end{macro}
%
% Later used \cs{AtBeginDocument}:
%    \begin{macrocode}
\cs_new:Nn \@@_open:nn
  {
    \prop_map_inline:Nn \g_@@_cc_prop
      {
        \iow_open:cn {g_auxdata_##1_#1_stream} {#2.aux.##1}
      }
  }
%    \end{macrocode}
%
% Later used \cs{AtEndDocument}:
%    \begin{macrocode}
\cs_new:Nn \@@_close:n
  {
    \prop_map_inline:Nn \g_@@_cc_prop
      {
        \iow_close:c {g_auxdata_##1_#1_stream}
      }
  }
%    \end{macrocode}
%
% \begin{macro}{\auxdata_split:n}
%    \begin{macrocode}
\cs_new:Nn \auxdata_split:n
  {

    \prop_map_inline:Nn \g_@@_cc_prop
      {
        \iow_now:ce { g_auxdata_ ##1 _ \g_@@_mainalt_tl _stream }
          {
            \exp_not:n
              {
                \csname\detokenize{auxdata_input:n}\endcsname {#1.aux.##1}
              }
            \cs_to_str:N \%
          }
      }

    \@@_open:nn {altn} {#1}
    \tl_gset:Nn \g_@@_mainalt_tl {altn}
  }
\cs_set_protected:Nn \auxdata_input:n { \tex_input:D #1\space }
\tl_new:N \g_@@_mainalt_tl
\tl_gset:Nn \g_@@_mainalt_tl {main}
%    \end{macrocode}
% \end{macro}
%
% \begin{macro}{\auxdata_main:}
%    \begin{macrocode}
\cs_new:Nn \auxdata_main:
  {
    \@@_close:n {altn}
    \tl_gset:Nn \g_@@_mainalt_tl {main}
  }
%    \end{macrocode}
% \end{macro}
%
% \subsection{Tags}
%
% \begin{macro}{\auxdata_new_tag:nn}
%    \begin{macrocode}
\cs_new:Nn \auxdata_new_tag:nn
  {
    \prop_if_in:NnT \g_@@_tags_prop {#1} {\ERROR2}
    \prop_gput:Nnn  \g_@@_tags_prop {#1} {#2}
    \seq_gput_right:cn {g_@@_cctags_ #2 _seq} {#1}
  }
%    \end{macrocode}
% \end{macro}
%
% \subsection{Writing}
%
% Do not allow writing to the data store in the preamble.
%    \begin{macrocode}
\cs_set:Nn \auxdata_write:nn           { \ERROR }
\cs_set:Nn \auxdata_write_shipout:nn   { \ERROR }
\cs_set:Nn \auxdata_write_shipout_x:nn { \ERROR }
%    \end{macrocode}
%
% \begin{macro}[internal]{\@@_setup_fn:}
% This is executed at begin document to enable writing.
% The "_shipout_x" variant needs an additional \cs{exp_not:N} because its contents are expanded at shipout as well as in the "x"-expansion as part of the definition.
%    \begin{macrocode}
\cs_set:Npn \@@_setup_fn:
 {
   \auxdata_new_write:NNn \auxdata_write:nn           \iow_now:ce       {}
   \auxdata_new_write:NNn \auxdata_write_shipout:nn   \iow_shipout:ce   {}
   \auxdata_new_write:NNn \auxdata_write_shipout_x:nn \iow_shipout_e:ce { \exp_not:N }

   \cs_undefine:N \@@_setup_fn:
 }
%    \end{macrocode}
% \begin{macro}[internal]{\auxdata_new_write:NNn}
% Creates a new writing function |#1|.
% Note that the data store could be read in any conceivable catcode regime (within reason), so the prefix command \cs{auxdata:nn} needs maximum sanitising.
%    \begin{macrocode}
\cs_set:Nn \auxdata_new_write:NNn
  {
    \cs_set_protected:Npn #1 ##1 ##2
      {
        \prop_get:NnNF \g_@@_tags_prop {##1} \l_auxdata_tl {\ERROR4}

        #2 { g_auxdata_ \l_auxdata_tl _ \g_@@_mainalt_tl _stream }
          {
            \exp_not:n { #3 \csname\detokenize{auxdata:nn}\endcsname }
              { \exp_not:n {##1} }
              { \exp_not:n {##2} }
            \cs_to_str:N \%
          }
      }
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
%
%
% \subsection{Reading}
%
% \begin{macro}{\auxdata_process_inline:nn}
% \begin{arguments}
% \item tag
% \item inline function
% \end{arguments}
% This is the main command for reading data from the data store.
% This function sets up an \enquote{anonymous} function with |#2|, then sets up the \enquote{doing} function in the data store to iterate over each entry with tag |#1|.
%
% I'm not sure if the endlinechar is necessary but it helps to avoid spurious spaces turning up!
%    \begin{macrocode}
\cs_new:Nn \auxdata_process_inline:nn
  {
    \file_if_exist:nT { \jobname.tag.#1 }
      {
        \cs_set:Npn \auxdata:n ##1 {#2}

        \prop_get:NnNF \g_@@_tags_prop {#1} \l_auxdata_this_ccname_tl {\ERROR}
        \prop_get:NVNF \g_@@_cc_prop \l_auxdata_this_ccname_tl \l_auxdata_cc_tl {\ERROR}

        \@@_catcodes_pushing:
        \l_auxdata_cc_tl
        \file_input:n { \jobname.tag.#1 }
        \@@_catcodes_pop:
      }
  }
%    \end{macrocode}
% \end{macro}
%
%
%
% \subsection{Final setup}
% \paragraph{At begin document}
% \begin{enumerate}
%  \item Read in the data for each tag for later checking.
%  \item Enable the write functions.
%  \item Open aux files for writing.
% \end{enumerate}
%    \begin{macrocode}
\AtBeginDocument
  {
    \@@_cache_previous:
    \@@_setup_fn:
    \@@_open:nn {main} {\jobname}
  }
%    \end{macrocode}
%
% \paragraph{At end document}
% \begin{enumerate}
%  \item Close all the data stores.
%  \item Save all auxiliary tag files for the next run.
%  \item Check whether data has changed.
% \end{enumerate}
%    \begin{macrocode}
\AtEndDocument
  {
    \@@_close:n {main}
    \@@_save_files:
    \@@_check_changes:
  }
%    \end{macrocode}
%
% \begin{macro}[internal]{\@@_cache_previous:}
% Read in the data stores for later \verb|\@@_check_changes:|.
%    \begin{macrocode}
\cs_new:Nn \@@_cache_previous:
  {
    \prop_map_inline:Nn \g_@@_tags_prop
      { \@@_input_aux:nn {##1} {cache} }
  }
%    \end{macrocode}
% \end{macro}
%
% \begin{macro}[internal]{\@@_check_changes:}
% Check if the data store is the same as last time.
% If not, probably need another compilation.
%    \begin{macrocode}
\cs_new:Npn \@@_check_changes:
  {
    \prop_map_inline:Nn \g_@@_tags_prop
      {
        \@@_input_aux:nn {##1} {final}
        \tl_if_eq:ccF { g_auxdata_ ##1 _final_tl } { g_auxdata_ ##1 _cache_tl }
          { \typeout{DATA~FOR~TAG~"##1"~HAS~CHANGED;~MAY~NEED~TO~RERUN~LATEX.} }
      }
  }
%    \end{macrocode}
% \end{macro}
%
% \begin{macro}[internal]{\@@_input_aux:nn}
% \begin{arguments}
% \item Data store.
% \item `name' suffix for tl that stores the data. ("cache" at beginning; "final" at end.)
% \end{arguments}
%
% Reading data from a file to a token list is done using \cs{file_get:nnN} then copying the result to the desired global token list.
% The biggest file size allowed by \TeX{} memory may perhaps be doubled by using an \texttt{x}-expanding version of \cs{file_get:nnN} and defining \cs{auxdata:nn} to expand to a non-expanding version of itself.  Memory could probably also be saved bystoring a hash of the previous auxdata and comparing it with the final one, or by other means.  In any case, until we encounter concrete use cases it is best not to optimize beyond reason.
%
% Probably \cs{@@_read_setup:} is not needed.
%    \begin{macrocode}
\cs_set:Nn \@@_input_aux:nn
  {
    \tl_set:Ne \l_auxdata_filename_tl {\jobname.tag.#1}
    \file_if_exist:nT \l_auxdata_filename_tl
      {
        \prop_get:NnNF \g_@@_tags_prop {#1} \l_auxdata_this_ccname_tl {\ERROR}
        \prop_get:NVNF \g_@@_cc_prop \l_auxdata_this_ccname_tl \l_auxdata_cc_tl {\ERROR}

        \file_get:nnN
          { \l_auxdata_filename_tl }
          { \@@_read_setup: \l_auxdata_cc_tl  }
          \l_@@_internal_tl
        \tl_gset_eq:cN
          { g_auxdata_ #1 _ #2 _tl }
          \l_@@_internal_tl
      }
  }
%    \end{macrocode}
% \end{macro}
%
% \begin{macro}[internal]{\@@_read_setup:}
% The \enquote{trick} referred to above.
%    \begin{macrocode}
\cs_set:Nn \@@_read_setup:
  {
    \cs_set:Npn \auxdata:n ##1
      { \exp_not:n { \auxdata:n {##1} } }
  }
%    \end{macrocode}
% \end{macro}
%
% \begin{macro}{\@@_save_files:}
%
% This function reads in the relevant aux files and saves their data to individual .tag. files, one per tag.
% It can handle the case when there are more tags than write registers, which involves inputting each aux file as many times as necessary.
% These files are then suitable to be read back in at the beginning of the next compilation or when necessary.
%
% For reference, we have
% \begin{itemize}
% \item |\g_@@_cc_prop| $\to$ [ccname/ccsetup]
% \item |\g_@@_tags_prop| $\to$ [tag/ccname]
% \item |{g_@@_cctags_ \meta{ccname} _seq}| $\to$ tags
% \end{itemize}
%
%    \begin{macrocode}
\int_new:N \l_@@_files_int
\int_new:N \l_@@_tags_int
\int_new:N \l_@@_groups_int
\seq_new:N \l_@@_tags_seq

\cs_set:Nn \@@_save_files:
  {
%<debug>    \typeout{=================}
%<debug>    \typeout{Writing~AXD~files}
%<debug>    \typeout{=================}
    \int_set:Nn \l_@@_files_int { \@@_iow_count_avail: }
%<debug>    \typeout{Have~\int_use:N \l_@@_files_int\space write~registers.}
    \int_step_inline:nn {\l_@@_files_int}
      {
        \exp_args:Nc \iow_new:N {g_@@_write_##1_stream}
        %% TODO: reuse other streams opened by this package
      }

    \cs_set:Npn \auxdata:nn ##1 ##2
      {
        \cs_if_exist_use:cT %% <- TODO fix doc bug for this function
          { auxdata_exec_ ##1 :nn } { {##1} {##2} }
      }

    \prop_map_inline:Nn \g_@@_cc_prop
      {
%<debug>        \typeout{===~Catcode~regime~##1~===}
        % need this many iterations to get all the tags covered by the number of files we have:
        \int_set:Nn \l_@@_groups_int
          {
            \fp_eval:n
              {
                ceil ( \seq_count:c {g_@@_cctags_ ##1 _seq} / \l_@@_files_int )
              }
          }
%<debug>        \typeout{Need~to~write~\seq_count:c {g_@@_cctags_ ##1 _seq}~tag(s);~will~take~\int_use:N \l_@@_groups_int\space iteration(s).}

        % iterate that many times:
        \int_step_inline:nn {\l_@@_groups_int}
          {
            \group_begin:
            ##2 % setup catcodes

            % setup each stream for corresponding tags:
            \int_step_inline:nn {\l_@@_files_int}
              {
                \seq_gpop_left:cNT {g_@@_cctags_ ##1 _seq} \l_@@_tag_tl
                  {
%<debug>                    \typeout{~-~Writing~\jobname.tag.\l_@@_tag_tl }

                    \iow_open:cn {g_@@_write_ ########1 _stream}
                      { \jobname.tag.\l_@@_tag_tl }

                    \cs_set:cpn { auxdata_exec_ \l_@@_tag_tl :nn }
                        ################1 ################2
                      {
                        \exp_args:Nc \iow_now:Ne {g_@@_write_ ########1 _stream}
                          {
                            \exp_not:n
                              {
                                \csname\detokenize{auxdata:n}\endcsname
                                  {################2}
                              }
                            \cs_to_str:N \%
                          }
                      }
                  }
              }

            % this does the writing:
            \file_input:n { \jobname.aux.##1 }

            % finish up:
            \int_step_inline:nn {\l_@@_files_int}
              { \iow_close:c {g_@@_write_ ########1 _stream} }

            \group_end:
          }
      }
  }
%    \end{macrocode}
% \end{macro}
%
%    \begin{macrocode}
%</pkg>
%    \end{macrocode}
%
% \PrintIndex
%
% \Finale

