\documentclass[a4paper]{ltugboat}

\usepackage{fancyvrb}
\usepackage{ifmtarg}
\usepackage{microtype}

\begin{document}
\title{DRAFT / A modern Lua test suite for \TeX\ programming}
\author{Frank Mittelbach, Will Robertson, \LaTeX3 team}
\address{%
  Mainz,  Germany\\
  Adelaide, Australia}
\netaddress{http://www.latex-project.org}



\newcommand\drivername{build.lua}
\newcommand\makename{l3build.lua}
\newcommand\execname{texlua \drivername}
\newcommand\compdirname{test/}

\setcounter{page}{777}

\newcommand\pdfTeX{pdf\TeX}
\newcommand\luaTeX{Lua\TeX}

\maketitle

\tableofcontents

\section{Introduction}

Regression tests are an important tool in any moderately complex
programming environment.  They allow the programmer to make extensive
changes to their code while providing confidence that something that
used to work still does.  Extensive regression test suites have been
an essential component of the maintenance and development of \LaTeXe{}
and \LaTeX3.

A regression test suite is typically composed of a number of
individual files that contain one or more testable units of the code
being tested. A testable unit might be either a certain computation
with an expected outcome, a series of logic tests, or --- in
particular for \TeX{}-based code --- material that is typeset and
intended to achieve some particular formatting.

During code development and before any new code is released to the
public, this test suite can be compiled to ensure that any changes to
the code have not introduced bugs or changed the behaviour compared to
previous versions.

As bugs in the code are reported, minimal examples demonstrating the
bug often form test files of their own, showing that the bug has been
fixed and won't re-occur in the future.

As \TeX{}-based code operates in at least three different `modes'
(mouth, stomach, and output), regression testing is more complex than
simply asserting the outcome of certain programming logic.  As part of
the work of the \LaTeX3 project, a new Lua-based testing environment
has been written to support ongoing development.  This testing
environment is suitable for use by the general community.


\section{History}

The ideas for a regression test suite for \LaTeX{} date back to the
early nineties when \LaTeX\,2.09 existed in various incompatible
flavours around the world due to its limitations in properly
supporting font selection, complex mathematics, and languages other
than English.  Because of that situation \LaTeXe{} was designed and
implemented to reunite the different format and to provide a stable
platform for future \LaTeX{} development.

However, to successfully introduce \LaTeXe{} as an accepted successor
of \LaTeX\,2.09 it was essential to win over the huge \LaTeX{} user
base and provide them with a system that was as stable and upward
compatible as possible. Thus existing user interfaces should be
preserved and typesetting should provide identical output except in
those cases were bug fixes or deliberate design decisions resulted in
changes.

To achieve this we devised a validation mechanism that could be used
to ensure that interfaces behave as expected and typesetting results
to not change even through the underlying code gets modified. With
this in place the \LaTeX3 Project Team together with a number of
further volunteers set out to provide a large number of test files and
verified them against the current \LaTeX\,2.09
implementation. Figure~\ref{fig:volunteers} shows the original request
for volunteers (exhibiting a severe underestimation of the amount of
work involved), see also \cite{tub???} for a more extensive
description. This effort resulted in something like 200 test files
that then got used to ensure ourselves that the new \LaTeXe{}
implementation was faithfully supporting all interfaces and it was one
of the key factors that the new system became an accepted replacement
for \LaTeX\,2.09 within a resonably short period.

\begin{figure}
\centering
\fbox{\begin{minipage}{.9\linewidth}
\textbf{Validating \LaTeX\,2.09}\\[\smallskipamount]
%
Writing test files for regression testing: checking bug fixes and
improvements to verify that they don't have undesirable side
effects; making sure that bug fixes really correct the problem
they were intended to correct; testing interaction with various
document styles, style options, and environments. We would
like three kinds of validation files:
\begin{enumerate}
\item General documents.
\item Exhaustive tests of special environments/modules such as
tables, displayed equations, theorems, floating figures,
pictures, etc.
\item Bug files containing tests of all bugs that are supposed to
be fixed (as well as those that are not fixed, with comments
about their status).
\end{enumerate}
A procedure for processing validation files has been devised;
details will be furnished to anyone interested in this task.
Estimated time required: 2 to 3 weeks, could be divided up.
\end{minipage}}
\caption{Original request for volunteers}\label{fig:volunteers}
\end{figure}

Once in place the regression test suite got augmented over time and
now contains roughly 350 test files altogether. Whenever a bug was
found and fixed we added a new test file that would undesired behavior
if that bug would somehow resurface through later changes. Though not
perfect (after all we introduced a number of bugs that initially were
not caught by the regression test suite), the aproach served us very
well and prevented a number of horrible mistakes that would otherwise
made it into public releases of \LaTeX.

\subsection{The needs in the '90s}

With the initial regression test suite we solved a number of burning
problems. First of all we wanted to be confident that the code and the
documented user interfaces worked as expected. Whenever we recoded
internal function the test suite would automatically alert us if that
resulted in any noticable changes on the user level or in downright
bugs. Furthermore \LaTeXe{} came with much more documentation and the
tests included compiling and checking that documentation for missing
reference and errors.

In addition the Makefiles that ran the tests also included goals to
build out the distribution automatically.  Compared to \LaTeX\,2.09
that consisted of very few files, the format for \LaTeXe{} was
generated from many source \texttt{.dtx} files, so the housekeeping
complexity was greatly increased.

Another issue we had to tackle was that the code was no longer
maintained by a single person but by developers living in different
places around the world and using different operating systems and
installations. So the regression suite had to function with different
installations.

Finally all tasks work without user intervention or manual work because
only in that case such a system is going to be used on a regular basis
and one will see benefits.

\subsection{The general approach}

Designing a test system for verifying \TeX's typesetting behavior is
not easy\Dash how do you test for correctness and how do you ensure
that the tests are repeatable over time and in different places?

The approach we came up with was to build test files that generate
suitable data in their \texttt{.log} files. Suitable data would be
state of counters or dimensions produced with \cs{showthe}, data
written with \cs{typeout}, or, for example, box content shown with
\cs{showbox}. Some of the tracing parameters of \TeX{} could be used to
verify paragraph building or page breaking decisions, but something
like \cs{tracingall} would be inadvisable, as it would show the
internal coding and not the expected functionality.

The result of running such a test file would then manually verified
and stored away as certified result. However, as we are all aware
\LaTeX's \texttt{.log} files contain a lot of irrelevant data some of
which differs from run to run and some of which differs when running
on different installations. So to make this approach workable we
introduced a cleanup step in which we modified the result files
removing irrelevant material and normalized some of the remaining
parts. Of course one has to be careful not to sanitize too far but we
found a number of things necessary or at least advisable, including
\begin{itemize}
\item  shortening file path info to avoid differences between
installations
\item drop empty lines (different \TeX{} implementations put
different amounts in)
\item drop line numbers in ``\texttt{on line <num>}'' to avoid difference
 just because extra lines got introduced in a test file.
\end{itemize}

Putting it all together we ended up with with a system consisting of
test files (with the extension \texttt{.lvt}), certified result files
to compare against (extension \texttt{.tlg}) and a fairly complex
Makefile and a number of Perl scripts used to run the different
tasks. These tasks included running the test suite, producing the
documentation and generating the distribution (ready to be shipped to
CTAN). It also contained a number of special functions such as
unpacking and locally installing the code, clean up the source
directories, checking individual test files or producing a new
\texttt{.tlg} file for a given test file.

\subsection{The new needs}

As mentioned above the initial system served us well, when cutting
over from \LaTeX\,2.09 to \LaTeXe{} and throughout the '90s that
showed very active \LaTeXe{} development with releases produced in
half-year intervals.

In this century development of the core of the \LaTeXe{} kernel slowed
down to a minimum (releases are now only every couple of years and the
changes are minimal) while it intensified in other areas such as
actively progressing the development of the \LaTeX3 programming
language \texttt{expl3}. With this new important requirements for a
regression test system became appearent.

Instead of a single distribution we now had to deal with a growing
number of distributions: core \LaTeXe{} and its packages, Babel (with
a different release cycle), \texttt{expl3} and possibily smaller and
larger distributions of third party code that also wanted to benefit
from a functional regression test system.

Windows or MacOS became the operating system of choice for several
developers and the Makefile approach of original test suite did not
work on Windows and only with modifications on MacOS.

Last not least a number of new \TeX-based engines matured and people
now wanted to use \LaTeX{} and friends not only on \pdfTeX{} but also
on these new engines all of which provided additional capabilities.
These new engines showed a number of subtle differences when adding
data to the \texttt{.log} file or due to extended capabilities showed
additional data (such as extra nodes in listings). Furthermore the new
engines still have bugs and a number of them showed up when we
initially ran test files and compared their output with the certified
\texttt{.tlg} data.

Thus testing became a multi-dimensional problem: one had to verify
test results with several engines and it had to work on multiple
operating systems. Furthermore new code sources posed new or different
requirements for building a distribution or doing the testing and
we soon found that the original approach made a number of hardwired
decision that were no longer applicable if the system was used with a
distribution different from \LaTeXe{}.

For a short while we tried to accomodate the need for Windows support
by using a set of \texttt{.bat} files in parallel with the Makefile
approach but obviously that was doomed to failure and hard to
maintain. Another avenue we explored was switching to a fully
Perl-based approach (using Cons) but that again didn't work well with
Windows and furthermore it would have been a solution not available
out of the box on any \TeX{} installation.

So in the end we decided to apply the same trick that was already used
ages ago with \texttt{docstrip.tex}: use the scripting language with
some operating system capabilities that is available out of the box on
all \TeX{} installations. Back then the answer was only \TeX{} itself
fit that bill and so \TeX{} became the tool to build style files
etc.\ from \texttt{.dtx} sources. However, while \TeX{} as such is too
limitied to be used for scripting a regression test system we now had
\luaTeX{} as an engine that offers a full fledged Lua interpreter\Dash
and these days \luaTeX{} is part of all modern \TeX{} installations.

Moving to Lua (or \texttt{texlua} to be precise) means that the test
and distribution system is now not tied either to the operating system
(as the script runs on Windows and Unix variants) or to third-party
tools (as Lua is available as part of a modern \TeX{} system).

\[
  * \quad * \quad *
\]

In the remaining sections of this article we describe the new system
and how it can be applied to support arbitrary code within the \TeX{}
world.

\section{Overview of the new system}
\label{sec:overview}

Consider an arbitrary package \textsf{abc} with a collection of source
files in the following layout.
\begin{Verbatim}
  abc/
      abc.dtx
      abc.ins
      build.lua
      README
      testfiles/
                test1.lvt
                test1.tlg
                ...
                support/
                        abc-test.cls
\end{Verbatim}
What is added in addition to the normal source files is short Lua script, normally called \texttt{\drivername}.
Test files and their certified results are located within folder
`\texttt{testfiles/}' with, resp., extensions \texttt{.lvt} and
\texttt{.tlg}.  The files in \texttt{support/} are used when running
the test files.  Upon running the test suite, a new folder
`\texttt{test}' is created in which the package is unpacked, support
files are copied across, and each test file is run in turn and
compared to their original \texttt{.tlg} file.

\subsection{Modes of testing}

The best way to perform regression tests for \TeX{} programming is to
use the \texttt{.log} file; only here can not just logical and
programmatic constructs be tested but box content as well.  Box
content is essential for checking from the very highest level that
code changes do not result in different typeset output.

\TeX{} programming can be either \emph{expandable} or not.  (The \TeX
book parlance for these terms is whether the processing occurs in
\TeX's mouth or stomach, respectively.)  Code that is expected to be
expandable should be tested as such.  This can be done by evaluating it within something like \cs{typeout} (in the case of \LaTeX), and for non-expandable tests one should output
their results once they have been evaluated.
%
As mentioned earlier there are a also number of \TeX{} tracing parameters
and commands like \cs{showbox}, \cs{showlists}, or \cs{showthe} that
can be used to generate relevant test data in the \texttt{.log} file.

To aid in producing a structure test suite we provide a number of
commands for use in the test files. \cs{TYPE} is used to write
material to the \texttt{.log} file; it works like \cs{typeout}, but it
allows `long' input.
%
A variety of commands, following, then use \cs{TYPE} to output strings
to the \texttt{.log} file.
\begin{itemize}
\item
\cs{SEPARATOR} inserts a long line of \texttt{=} symbols to break up
the output.
\item
\cs{TRUE}, \cs{FALSE}, \cs{YES}, \cs{NO} output what you'd expect.
\item
\cs{ERROR} is not defined but is commonly used to indicate a code path
that should never be reached.
\end{itemize}
To produce individual tests we offer the commands \cs{TEST} and
\cs{TESTEXP}. These commands take two arguments, respectively: a title
and the actual test body.  \cs{TESTEXP} executes the body within a
\cs{TYPE} command to test expandability but with \cs{TEST} you are
responsible to generate test output using \cs{TYPE}, \cs{TRUE},
etc.\ as it is intended to be used for non-expandable tests.

\textit{FMi: replace test example}
  
Finally, the \cs{TEST} command  surrounds its contents with some \cs{SEPARATOR}s and a title.
\begin{Verbatim}
\begin{TEST}{bool_set,~lazy~evaluation}
  \bool_set:Nn \l_tmpa_bool
   {
    \int_compare_p:nNn 1=1
    && \bool_if_p:n
     {
      \int_compare_p:nNn 2=3 ||
      \int_compare_p:nNn 4=4 ||
      \int_compare_p:nNn 1=\ERROR % is skipped
     }
    && \int_compare_p:nNn 2=2
   }
  \bool_if:NTF \l_tmpa_bool \TRUE \FALSE
\end{TEST}
\end{Verbatim}
This test will produce the following in the output.
\begin{Verbatim}
==========================================
TEST 8: bool_set, lazy evaluation
==========================================
TRUE
==========================================
\end{Verbatim}
(Only if it's the eighth test in the file of course.)

\section{Use of the regression test system}

Consider the case that a \LaTeX\ package consists of one or more
\texttt{.dtx} files, say, in a flat directory structure.  By default,
to set up a regression test suite, you would create a driver file
named `\texttt{\drivername}' and sub-folder named
`\texttt{testfiles/}' to contain the test files.  An example driver
file is shown in Section~\ref{sec:example}.

The test files can be called basically anything (but should be logical
in some way), and must have extension \texttt{.lvt}.  These are
accompanied by a pre-saved \texttt{.tlg} file which contains the
`results' of the test file to be checked against subsequent
compilation of that test.


\subsection{Creating test output and checking tests}

The first time a \texttt{.lvt} test file is written, it will need to
be compiled to obtain the necessary \texttt{.tlg} output for future
tests.  This is performed with:
\begin{quote}\ttfamily
\execname~save~\meta{test name}
\end{quote}
This command can be re-run as many times as necessary until the test
file demonstrates the necessary behaviour being tested.

At this point, 
\begin{quote}\ttfamily
\execname~check~\meta{test name}
\end{quote}
will then re-run the \texttt{.lvt} file and compare the result to the
original \texttt{.tlg} output.  Presuming no code has changed to
affect the output of the test, the console output of this command will
be the usual console output from a \TeX{} compilation followed by
\begin{quote}\ttfamily
~~Check passes
\end{quote}
These compilations take place in the subdirectory
`\texttt{\compdirname}', and if a test fails a diff file is deposited
here with the information about what has changed in the output of the
test file.


\subsection{An example driver file}
\label{sec:example}

For a simple case such as shown in the overview in
Section~\ref{sec:overview}, the driver file (\texttt{\drivername}) is
quite simple.  An example of a driver file is shown in
Figure~\ref{fig:driver}; it need do little more than inform the build
system the name of the package and set some flags according to whether
the regression tests should use a standard \texttt{texmf} tree or not.

\begin{figure}
\begin{Verbatim}[frame=single,fontsize=\small]
#!/usr/bin/env texlua

-- Make script for breqn

module = "breqn"

cleanfiles  = {"*.zip"} -- don't delete PDFs

-- #################### --
-- Run the build system --

kpse.set_program_name(arg[-1])
buildscript = kpse.lookup("l3build.lua")
scriptname = arg[0]
dofile (buildscript)
\end{Verbatim}
\caption{Driver file for the \textsf{breqn} package.}
\label{fig:driver}
\end{figure}


\subsection{Structure of test files}

As mentioned previously, the method of using the \texttt{.log} file
allows various types of tests to be conducted.  The most simple test
might load a package and execute some commands to produce a small
section of typeset output.  A complete example of such a test is shown
in Figure~\ref{fig:breqn}.  Some points to note.
\begin{enumerate}
\item The first line, \verb|\input{regression-test}| loads the
  necessary settings and commands to format the \texttt{.log} file
  properly for testing.
\item It is not necessary to load a particular document class; a
  package author may wish to adjust page margins, etc., without
  repeating the commands for each test.
\item The test begins proper at \cs{START}, and \cs{AUTHOR} is an
  optional way of indicating who might know how to fix the problem
  should the test ever begin failing.
\item \cs{showoutput} prints the contents of the page to the
  \texttt{.log} file.
\item \cs{END}, \emph{not} the stardard \verb|\end{document}| tidies
  up nicely.
\end{enumerate}
Not shown is the \cs{OMIT} \dots \cs{TIMO} construction, which puts
flags into the \texttt{.log} file between which no test comparisons
should be made.  This can be used when, say, loading maths fonts for
the first time in a \LaTeX{} document halfway through a test.

\begin{figure}
\begin{Verbatim}[frame=single,fontsize=\small]
\input{regression-test}

\documentclass{breqn-test}
\usepackage{breqn}
\begin{document}

\START
\AUTHOR{Will Robertson}

\begin{dmath}
a+b+c+d+e+f+g+h+i+j+k+l+m+
  n+o+p+q+r+s+t+u+v+w+x+y+z
\end{dmath}

\showoutput
\newpage
\END
\end{Verbatim}
\caption{Example test from \textsf{breqn}.}
\label{fig:breqn}
\end{figure}

An example of a more structured test is shown in
Figure~\ref{fig:nonexp}.  Here, a number of different tests are
contained within a single file, and one of these is included in the
example.  The content of the test is not important here, except to
note that the output is logged using the command \verb|\cs_show:N|
(similar to \TeX's primitive \cs{show}) \Dash since this command
prints output to the \texttt{.log} file, no explicit \cs{TYPE}
commands are required.  Note also that test files are run in
`\texttt{nonstopmode}', so commands such as \cs{show} that would
normally pause typesetting here do not.

\begin{figure}
\begin{Verbatim}[frame=single,fontsize=\small]
\input{regression-test}
\documentclass{minimal}
\RequirePackage{expl3}
\begin{document}
\START
\AUTHOR{LaTeX3 Project}
\ExplSyntaxOn

% more tests here omitted

\begin{TEST}{Char~set~active~(setting)}
  \char_set_active:Npn A  { Works }
  \char_gset_active:Npn B { Works }
  \group_begin:
    \char_set_active:Npn  C { Works }
    \char_gset_active:Npn D { Works }
  \group_end:
  
  \cs_show:N A
  \cs_show:N B
  \SEPARATOR
  \cs_show:N C
  \cs_show:N D
\end{TEST}
\end{Verbatim}
\caption{Example of a non-expandable test.}
\label{fig:nonexp}
\end{figure}


\section{Options}

While the examples shown previously show the behaviour in the simplest
cases, the new build system provides significantly greater
flexibility.

\makeatletter
\newcommand\makeopt[3][]{\paragraph{\texttt{#2}} #3 \@ifmtarg{#1}{}{\leavevmode\\{\raggedright Default: \ttfamily = #1\par}}}

\subsection{Names and directories}

\makeopt[]{bundle}{The name of the main bundle (e.g.,\\ `\texttt{l3packages}').}
\makeopt[]{module}{The name of the package/module (e.g., `\texttt{xparse}').}

\makeopt{maindir} {Path to the top level of the current bundle.}

\makeopt{testfiledir} {Where the test files are located.}

\makeopt{testdir} {Where the tests are compiled.}

\subsection{File lists}

\makeopt[\{"*.pdf", "*.zip"\}]{binaryfiles}{}
\makeopt[\{\}]{checkfiles} {Extra files unpacked purely for tests.}
\makeopt[\{"*.dtx"\}]{cmdcheckfiles}{}
\makeopt[\{\}]{demofiles}{}
\makeopt[\{"*.pdf", "*.zip"\}]{cleanfiles} {Files removed by the \texttt{clean} target.}
\makeopt[\{"*\string~"\}]{excludefiles}{}
\makeopt[\{"*.sty"\}]{installfiles}{}
\makeopt[\{"*.dtx", "*.ins"\}]{sourcefiles}{}
\makeopt[\{"*.cls", "*.lua", "*.sty", "*.tex"\}]{supportfiles}{}
\makeopt[\{"*.markdown"\}]{txtfiles}{}
\makeopt[\{"*.dtx"\}]{typesetfiles}{}
\makeopt[\{"*.ins"\}]{unpackfiles} {Files to actually unpack.}

\subsection{Dependencies}

Packages that need their own unpacking, etc., to support building the
current module.

\makeopt[\{ \}]{checkdeps}{}
\makeopt[\{ \}]{typesetdeps}{}
\makeopt[\{ \}]{unpackdeps}{}

\subsection{Executables and their options}

\makeopt[pdflatex]{typesetexe}{Command to typeset documentation.}
\makeopt[tex]{unpackexe}{Command to execute on unpack files such as \texttt{.ins}.}
\makeopt[zipexe]{zipexe}{Self explanatory.}

\makeopt["-interaction=batchmode"]{checkopts}{Option passed to the executable for compiling each test.}
\makeopt["-interaction=batchmode"]{cmdchkopts}{Option passed to the executable for compiling the `check commands' test.}
\makeopt["-interaction=nonstopmode"]{typesetopts}{Option passed to the executable for compiling the documentation.}
\makeopt[""]{unpackopts}{Option passed to the executable for unpacking the bundle.}
\makeopt["-v -r -X"]{zipopts}{Self-explanatory.}

\subsection{Testing}

\makeopt[\{{"pdftex", "xetex", "luatex"}\}]{chkengines}{Engines used to test each test file.}
\makeopt["pdftex"]{stdengine}{The standard engine for testing.}


\subsection{Other}

\makeopt[1]{checkruns}{Number of times to compile each test file.}
\makeopt[""]{typesetcmds}{\TeX{} input to pass into the typeset documentation.}
\makeopt[build.lua]{scriptname}{Name of the build files in each directory of the bundle (n.b., they must all be the same). [[Will: this is automatable with \texttt{arg[0]} so I'm not sure if this is necessary any more.]]}




\section{Acknowledgements}

The original test suite system was a joint effort by the whole
\LaTeX{} project team at that time, i.e.,
%
Frank Mittelbach,
Rainer Sch\"opf,
David Carlisle,
Michael Downes,
Alan Jeffrey, and
Chris Rowley.
%
We also had a lot of help when writing the initial set of test files from a
number of volunteers in particular Daniel Flipo and Chris Martin.

Around 2008 Rainer replaced the Makefile approach used for \LaTeXe{}
by Cons (a Perl-based solution) as the Makefile got so complex over
time that it was difficult to manage.

For the \LaTeX3 development with stayed with Make as the requirements
of the \texttt{expl3} distribution were initially much simpler.

Joseph Wright wrote a first set of \texttt{.bat} files for
\texttt{expl3}, as by then many developers worked on Windows. Modeled
after this Frank replaced the Cons solution for \LaTeXe{} in 2013.

Finally in 2014 Joseph then implemented most of the new Lua-based
system and it is now successfully used to manage the \LaTeX3
(\texttt{expl3}) distribution as well as several smaller package
distributions. The \LaTeXe{} distribution will follow shortly.



\begin{thebibliography}{9}
\bibitem[1]{label} foo
\end{thebibliography}


\bigskip
\makesignature



\end{document}
